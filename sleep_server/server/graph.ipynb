{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "import os\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import manifold, mixture, cluster\n",
    "from sqlalchemy import func, select as sqlselect, distinct, text as sqltext\n",
    "from matplotlib import pylab\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import networkx as nx\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import functools\n",
    "import random\n",
    "import operator\n",
    "from itertools import islice\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "os.sys.path.insert(0,parentdir)\n",
    "\n",
    "from api import app, db\n",
    "import importlib\n",
    "#importlib.reload(models)\n",
    "#Genre, Artist, Song, ArtistGenres, SongTracks, SongGroup, Group, SimilarGenre\n",
    "from server.models import *\n",
    "from server import song_helper\n",
    "importlib.reload(song_helper)\n",
    "\n",
    "%matplotlib inline\n",
    "genres, genres_name = song_helper.db_get_genres()\n",
    "genres[0] = '-unk-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = ['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'loudness', \n",
    "                'valence', 'danceability', 'key', 'mode', 'time_signature']\n",
    "\n",
    "\n",
    "def select_top_songs():\n",
    "    return db.session.query(Song).filter(Song.IsToplistSong == 1)\n",
    "def count_top_songs():\n",
    "    return db.session.query(func.count(Song.SongId)).filter(Song.IsToplistSong == 1).scalar()\n",
    "\n",
    "\n",
    "\n",
    "def select_song_group(group_id):\n",
    "    def select_song_group_i():\n",
    "        return db.session.query(Song).join(SongGroup).filter(SongGroup.GroupId == group_id)\n",
    "    return select_song_group_i\n",
    "\n",
    "\n",
    "def count_song_group(group_id):\n",
    "    def count_song_group_i():\n",
    "        return db.session.query(func.count(Song.SongId)).join(SongGroup).filter(SongGroup.GroupId == group_id).scalar()\n",
    "    return count_song_group_i\n",
    "\n",
    "\n",
    "def select_song_group_type(group_type):\n",
    "    def select_song_group_type_i():\n",
    "        return db.session.query(Song).join(SongGroup).join(Group).filter(Group.Type == group_type).distinct()\n",
    "    return select_song_group_type_i\n",
    "\n",
    "\n",
    "def count_song_group_type(group_type):\n",
    "    def count_song_group_type_i():\n",
    "        return db.session.query(func.count(distinct(Song.SongId))).join(SongGroup).join(Group).filter(Group.Type == group_type).scalar()\n",
    "    return count_song_group_type_i\n",
    "\n",
    "\n",
    "song_in_genre_q = \"EXISTS (SELECT 1 FROM Artists a JOIN ArtistGenres ag ON a.ArtistId \"\\\n",
    "                  \"= ag.ArtistId WHERE a.ArtistId = Songs.ArtistId AND ag.GenreId = %i)\"\n",
    "def select_song_in_genre(genre_id, limit):\n",
    "    def select_song_in_genre_i():\n",
    "        return db.session.query(Song).filter(sqltext(song_in_genre_q % genre_id)).order_by(Song.Hotness).limit(limit)\n",
    "    return select_song_in_genre_i\n",
    "\n",
    "\n",
    "def count_song_in_genre(genre_id, limit):\n",
    "    def count_song_in_genre_i():\n",
    "        return min(db.session.query(func.count(distinct(Song.SongId))).filter(sqltext(song_in_genre_q % genre_id)).scalar(), limit)\n",
    "                        \n",
    "    return count_song_in_genre_i\n",
    "\n",
    "\n",
    "def load_songs(select, count):\n",
    "    songs_count = count()\n",
    "    # print('will load %i songs' % songs_count)    \n",
    "    song_names = {}\n",
    "    song_features = np.ndarray((songs_count, 16), dtype=np.float32)    \n",
    "    row = 0\n",
    "    for song in select():\n",
    "        song_features[row, 0] = isnull(song.AS_energy)\n",
    "        song_features[row, 1] = isnull(song.AS_liveness)\n",
    "        song_features[row, 2] = isnull(song.AS_tempo)\n",
    "        song_features[row, 3] = isnull(song.AS_speechiness)\n",
    "        song_features[row, 4] = isnull(song.AS_acousticness)\n",
    "        song_features[row, 5] = isnull(song.AS_instrumentalness)\n",
    "        song_features[row, 6] = isnull(song.AS_loudness)\n",
    "        song_features[row, 7] = isnull(song.AS_valence)\n",
    "        song_features[row, 8] = isnull(song.AS_danceability)\n",
    "        song_features[row, 9] = isnull(song.AS_key)\n",
    "        song_features[row, 10] = isnull(song.AS_mode)\n",
    "        song_features[row, 11] = isnull(song.AS_time_signature)\n",
    "        song_features[row, 12] = song.DurationMs\n",
    "        song_features[row, 13] = song.SongId\n",
    "        song_features[row, 14] = 0 if song.Genre is None else song.GenreId\n",
    "        song_features[row, 15] = song.ArtistId\n",
    "        \n",
    "        song_names[song.SongId] = song.Name        \n",
    "        row += 1\n",
    "    if row != songs_count:\n",
    "        raise Exception('got %i songs, expected %i' % (row, songs_count))\n",
    "        \n",
    "    return song_features, song_names\n",
    "\n",
    "\n",
    "def load_artist_genres():\n",
    "    s = sqlselect([ArtistGenres.GenreId, ArtistGenres.ArtistId]).order_by(ArtistGenres.ArtistId)\\\n",
    "                                                                .order_by(ArtistGenres.Ord)\n",
    "    rows = db.session.execute(s).fetchall()\n",
    "    a_genres = {}\n",
    "    for row in rows:\n",
    "        if row[1] not in a_genres:\n",
    "            a_genres[row[1]] = [row[0]]\n",
    "        else:\n",
    "            a_genres[row[1]].append(row[0])\n",
    "    return a_genres\n",
    "\n",
    "\n",
    "def load_similar_genres():\n",
    "    s = sqlselect([SimilarGenre])\n",
    "    rows = db.session.execute(s).fetchall()\n",
    "    s_genres = {}\n",
    "    for row in rows:\n",
    "        if row[0] not in s_genres:\n",
    "            s_genres[row[0]] = [(row[1], row[2])]\n",
    "        else:\n",
    "            s_genres[row[0]].append((row[1], row[2]))\n",
    "    return s_genres\n",
    "\n",
    "\n",
    "def load_similar_artists(artist_id):\n",
    "    txt = 'SELECT SimilarArtistId FROM SimilarArtists WHERE ArtistId = %i ORDER BY Dist' % artist_id    \n",
    "    s = sqltext(txt)    \n",
    "    rows = db.session.execute(s).fetchall()    \n",
    "    return [row[0] for row in rows]\n",
    "    \n",
    "\n",
    "def get_artists_name(artist_id):\n",
    "    s = sqltext('SELECT Name FROM Artists WHERE ArtistId = %i' % artist_id)\n",
    "    row = db.session.execute(s).fetchone()\n",
    "    return row[0]\n",
    "    \n",
    "\n",
    "def isnull(v, r=0):\n",
    "    return v if v is not None else 0\n",
    "    \n",
    "\n",
    "def plot(projection, labels, annotate=True, color=None, plot_size=15):\n",
    "    #assert projection.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    pylab.figure(figsize=(plot_size, plot_size))  # in inches\n",
    "    for l_id in labels:\n",
    "        x, y = projection[l_id-1,:]\n",
    "        if color is not None:\n",
    "            pylab.scatter(x,y, c=color[i], s=500, cmap='gray')\n",
    "        else:\n",
    "            pylab.scatter(x, y)\n",
    "        if annotate:\n",
    "            pylab.annotate(labels[l_id], xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                           ha='right', va='bottom')\n",
    "    pylab.show()\n",
    "    \n",
    "    \n",
    "def plot2(projection, labels, annotate=True, color=None):\n",
    "    assert projection.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    pylab.figure(figsize=(15,15))  # in inches\n",
    "    pylab.scatter(projection[:,0],projection[:,1], c=color, s=30)\n",
    "    #pylab.colorbar()\n",
    "    pylab.show()\n",
    "    \n",
    "def plot3(projection, labels, color):    \n",
    "    pylab.figure(figsize=(15,10))  # in inches\n",
    "    max_color = np.max(color)\n",
    "    jet = cm = pylab.get_cmap('jet')\n",
    "    cNorm  = colors.Normalize(vmin=0, vmax=max_color)\n",
    "    scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "    \n",
    "    # display color by color\n",
    "    for c in list(np.unique(color)):\n",
    "        col = scalarMap.to_rgba(c)\n",
    "        pylab.scatter(projection[color == c,0], projection[color==c,1],c=col, s=30,\n",
    "                      label=labels[c])#'color: (%4.2f,%4.2f,%4.2f)'%(col[0],col[1],col[2]))\n",
    "        \n",
    "    \n",
    "    pylab.legend()\n",
    "    pylab.show()\n",
    "    \n",
    "\n",
    "def tsne_projection(song_features):\n",
    "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "    return tsne.fit_transform(song_features)\n",
    "    \n",
    "\n",
    "def prepare_songs(song_features, scaler=None):\n",
    "    permutation = np.random.permutation(song_features.shape[0])\n",
    "    song_features = song_features[permutation,:]\n",
    "    song_genres = song_features[:,14]\n",
    "    # normalize features\n",
    "    normalized_features = song_features[:,0:9]\n",
    "    features_mean = np.mean(normalized_features, axis=0)\n",
    "    features_std = np.std(normalized_features, axis=0)\n",
    "    scaler = scaler or sklearn.preprocessing.StandardScaler(copy=False).fit(normalized_features)\n",
    "    scaler.transform(normalized_features)    \n",
    "    return song_features, song_genres, features_mean, features_std, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_features, song_names = load_songs(select_top_songs, count_top_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_features, song_genres, features_mean, features_std, features_scaler = prepare_songs(song_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featured_features = [0,1,2,3,4,5,7,8]\n",
    "feature_minimum = np.min(song_features, axis=0)\n",
    "feature_maximum = np.max(song_features, axis=0)\n",
    "\n",
    "\n",
    "def print_features(f_vec):\n",
    "    for i in range(min(len(feature_names),len(f_vec))):\n",
    "        print('%s: %i%% (%f)'%(feature_names[i], (f_vec[i] - feature_minimum[i])*100/(feature_maximum[i] - \n",
    "                                                                                    feature_minimum[i]), f_vec[i]))\n",
    "        \n",
    "def get_core_genres(gr_song_genres, describe=True):\n",
    "    # print(gr_song_genres[gr_song_genres < 0])\n",
    "    gr_g_array = np.array(gr_song_genres, dtype=np.int64)\n",
    "    gr_g_bins = np.bincount(gr_g_array)\n",
    "    gr_g_bin_sort = np.argsort(gr_g_bins)[::-1]\n",
    "    # get maximum 20 genres\n",
    "    min_g_count = 1\n",
    "    if len(gr_g_bin_sort) > 20:\n",
    "        min_g_count = max(gr_g_bins[gr_g_bin_sort[20]], 1)\n",
    "    if describe:\n",
    "        for sort_id in gr_g_bin_sort:\n",
    "            c = gr_g_bins[sort_id]\n",
    "            if c >= min_g_count:\n",
    "                print ('Genre %s count %i' % (genres[sort_id], c))\n",
    "\n",
    "    gr_top_g = gr_g_bin_sort[gr_g_bins[gr_g_bin_sort] >= min_g_count]\n",
    "    # print(gr_top_g)\n",
    "    # print(len(gr_song_genres))\n",
    "    # print(len(gr_song_genres[gr_song_genres>=0]))\n",
    "    # print(gr_song_genres[gr_song_genres>=0])\n",
    "    # print(str(gr_song_genres))\n",
    "    gr_top_g_indexer = np.ndarray(len(gr_song_genres), dtype=np.bool)    \n",
    "    for i, g in enumerate(gr_song_genres):\n",
    "        gr_top_g_indexer[i] = g in gr_top_g and g != 0\n",
    "        \n",
    "    return gr_top_g_indexer\n",
    "        \n",
    "        \n",
    "def outliers_info(features, core_features, gr_song_features, gr_song_names, genres):\n",
    "    # novelty detection\n",
    "    clf = sklearn.svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "    clf.fit(core_features) # gr_song_features[gr_top_g_indexer][:,featured_features]\n",
    "    y_pred_train = clf.predict(features)\n",
    "    print('%% of outliers in dataset: %f%%' % (y_pred_train[y_pred_train == -1].size * 100.0 / features.shape[0]))\n",
    "    y_decision_train = clf.decision_function(features)[:,0]\n",
    "    y_decision_train_sort = np.argsort(y_decision_train)\n",
    "    for sort_id in y_decision_train_sort[:20]:\n",
    "        if y_pred_train[sort_id] == -1:\n",
    "            song = gr_song_features[sort_id]\n",
    "            print('song %s-%s(%i) is outlier with dist %f' % (gr_song_names[song[13]], genres[song[14]],\n",
    "                                                              song[13], y_decision_train[sort_id]))\n",
    "    print('most crazy outlier')\n",
    "    print(print_features(gr_song_features[y_decision_train_sort[0],0:9]))\n",
    "\n",
    "    print('')\n",
    "    y_decision_train_sort = y_decision_train_sort[::-1]\n",
    "    for sort_id in y_decision_train_sort[:20]:\n",
    "        if y_pred_train[sort_id] == 1:\n",
    "            song = gr_song_features[sort_id]\n",
    "            print('song %s-%s(%i) is ingroup with dist %f' % (gr_song_names[song[13]], genres[song[14]],\n",
    "                                                              song[13], y_decision_train[sort_id]))\n",
    "    print('most ingrouped')\n",
    "    print(print_features(gr_song_features[y_decision_train_sort[0],0:9]))\n",
    "    # y_pred_top = clf.predict(gr_song_features[gr_top_g_indexer][:,0:9])\n",
    "    # print(y_pred_top[y_pred_top == -1].size * 100.0 / gr_song_features[gr_top_g_indexer].shape[0])\n",
    "\n",
    "\n",
    "def plot_clusters(projection, y_pred):\n",
    "    y_pred = y_pred + 1\n",
    "    y_pred_bc = np.bincount(y_pred)\n",
    "    n_c = len(y_pred_bc)\n",
    "    print('count elements in clusters %s' % str(y_pred_bc))\n",
    "    components = {0: 'noise samples'}\n",
    "    for c in range(1, n_c+1):\n",
    "        components[c] = 'component %i' % c    \n",
    "    plot3(projection, components, color=y_pred)\n",
    "    \n",
    "    \n",
    "def fit_dpgmm(features, n_components=8):        \n",
    "    # choose best model: commented out as GMM is clearly inferior\n",
    "    # lowest_bic = np.infty\n",
    "    # bic = []\n",
    "    # n_components_range = range(1, 10)\n",
    "    #cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "    #for cv_type in cv_types:\n",
    "    #    for n_components in n_components_range:\n",
    "    #        # Fit a mixture of Gaussians with EM\n",
    "    #        gmm = mixture.GMM(n_components=n_components, covariance_type=cv_type, n_iter=1000)\n",
    "    #        gmm.fit(features)\n",
    "    #        bic.append(gmm.bic(features))\n",
    "    #        if bic[-1] < lowest_bic:\n",
    "    #            lowest_bic = bic[-1]\n",
    "    #            best_gmm = gmm\n",
    "    # y_pred = best_gmm.predict(features)\n",
    "    \n",
    "    # Fit a Dirichlet process mixture \n",
    "    dpgmm = sklearn.mixture.DPGMM(n_components=n_components, covariance_type='tied', n_iter=1000, verbose=0) #, alpha=5\n",
    "    dpgmm.fit(features)\n",
    "    y_pred = dpgmm.predict(features)\n",
    "    return y_pred\n",
    "    \n",
    "    \n",
    "def fit_DBSCAN(features, eps=0.5, min_samples=20):\n",
    "    cls = sklearn.cluster.DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    cls.fit(features)\n",
    "    y_pred = cls.labels_\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    # n_clusters_ = len(set(y_pred)) - (1 if -1 in y_pred else 0)\n",
    "    # plot_clusters(features, y_pred, n_clusters_)\n",
    "    return y_pred\n",
    "    \n",
    "\n",
    "def fit_affinity_prop(features):\n",
    "    cls = sklearn.cluster.AffinityPropagation(preference=-60)\n",
    "    cls.fit(features)\n",
    "    y_pred = cls.labels_\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    # cluster_centers_indices = cls.cluster_centers_indices_\n",
    "    # n_clusters_ = len(cluster_centers_indices)\n",
    "    # plot_clusters(features, y_pred, n_clusters_)\n",
    "    return y_pred\n",
    "    \n",
    "\n",
    "def kmeans_gap_statistics(df, max_k):\n",
    "    # https://datasciencelab.wordpress.com/2013/12/27/finding-the-k-in-k-means-clustering/\n",
    "    # https://github.com/Zelazny7/gap-statistic/blob/master/gap.py\n",
    "    def get_rand_data(col):\n",
    "        rng = col.max() - col.min()\n",
    "        return np.random.random_sample(len(col))*rng + col.min()\n",
    "    \n",
    "    def iter_kmeans(refs, n_clusters):\n",
    "        vals = np.zeros(len(refs))\n",
    "        k = sklearn.cluster.KMeans(n_clusters=n_clusters)\n",
    "        for i in range(len(refs)):            \n",
    "            k.fit(refs[i])\n",
    "            # print('Ref k: %s' % k.get_params()['n_clusters'])\n",
    "            vals[i] = k.inertia_\n",
    "        return vals\n",
    "    \n",
    "    gaps = np.zeros(max_k)\n",
    "    sks = np.zeros(max_k)\n",
    "    B = 10 # number of test data sets\n",
    "    refs = [np.apply_along_axis(get_rand_data, 0, df) for b in range(B)]\n",
    "    print(len(refs))\n",
    "    for k in range(max_k):\n",
    "        km_act = sklearn.cluster.KMeans(n_clusters=k+1)\n",
    "        km_act.fit(df)\n",
    "        logWk = np.log(km_act.inertia_)        \n",
    "        logWkbs = np.log(iter_kmeans(refs, n_clusters=k+1))\n",
    "        logWkb = sum(logWkbs)/B\n",
    "        gaps[k] = logWkb - logWk        \n",
    "        sks[k] = np.sqrt(sum((logWkbs-logWkb)**2)/B)*np.sqrt(1+1/B)\n",
    "        print('logWkb: %f   logWk: %f  gap: %f sks: %f delta: %f' %\n",
    "              ( logWkb, logWk, gaps[k], sks[k], gaps[k]-sks[k]))            \n",
    "    \n",
    "    for n_clusters_ in range(max_k-1):\n",
    "        if gaps[n_clusters_] > gaps[n_clusters_+1] - sks[n_clusters_+1]:\n",
    "            break\n",
    "    return n_clusters_+1\n",
    "\n",
    "\n",
    "def kmeans_f_of_K(features, max_k):\n",
    "    def f_of_K(X, ck, Skm1=0):    \n",
    "        # http://www.ee.columbia.edu/~dpwe/papers/PhamDN05-kmeans.pdf\n",
    "        # https://datasciencelab.wordpress.com/2014/01/21/selection-of-k-in-k-means-clustering-reloaded/\n",
    "        # http://www.stat.cmu.edu/~ryantibs/datamining/lectures/06-clus3.pdf\n",
    "        Nd = X.shape[1]\n",
    "        # print(Nd)\n",
    "        a = lambda k, Nd: 1 - 3/(4*Nd) if k == 2 else a(k-1, Nd) + (1-a(k-1, Nd))/6\n",
    "        km = sklearn.cluster.KMeans(n_clusters=ck)\n",
    "        km.fit(X)\n",
    "        #dists = km.transform(X)\n",
    "        #Sk = 0\n",
    "        #for k in range(ck):\n",
    "        #    Sk += sum(dists[km.labels_==k, k])\n",
    "        clusters = km.labels_\n",
    "        mu = km.cluster_centers_\n",
    "        # print(mu)\n",
    "        Sk = sum([np.linalg.norm(mu[i]-c)**2 for i in range(ck) for c in X[clusters==i]])\n",
    "        if ck == 1:\n",
    "            fs = 1\n",
    "        elif Skm1 == 0:\n",
    "            fs = 1\n",
    "        else:\n",
    "            fs = Sk/(a(ck,Nd)*Skm1)\n",
    "        return fs, Sk \n",
    "\n",
    "    fs = np.zeros(max_k)\n",
    "    fs[0], Sk = f_of_K(features, 1)\n",
    "    for k in range(2, max_k+1):\n",
    "        fs[k-1], Sk = f_of_K(features, k, Skm1=Sk)\n",
    "        print('clusters %i f_of_K %f' % (k, fs[k-1]))\n",
    "    # print(fs)\n",
    "    return np.argmin(fs) + 1\n",
    "\n",
    "\n",
    "def kmeans_silhouette(features, max_k):\n",
    "    best_n_clusters = None\n",
    "    best_score = -1 # worst possible\n",
    "\n",
    "    for n_clusters_ in range(2, max_k+1):\n",
    "        cls = sklearn.cluster.KMeans(n_clusters=n_clusters_)\n",
    "        cls.fit(features)\n",
    "        y_pred = cls.labels_\n",
    "        score = sklearn.metrics.silhouette_score(features, y_pred)\n",
    "        print('%i clusters score %f' % (n_clusters_, score))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_n_clusters = n_clusters_    \n",
    "\n",
    "    return best_n_clusters\n",
    "\n",
    "\n",
    "def fit_kmeans(features, n_clusters_):\n",
    "    cls = sklearn.cluster.KMeans(n_clusters=n_clusters_)\n",
    "    cls.fit(features)\n",
    "    y_pred = cls.labels_\n",
    "    # plot_clusters(features, y_pred, n_clusters_)\n",
    "    return y_pred\n",
    "    \n",
    "    \n",
    "def describe_songs(gr_song_features, gr_song_names, gr_song_genres, distance_mod=[1,1,1,1,1,1,1,1]):    \n",
    "    features = gr_song_features[:,featured_features]\n",
    "    weighted_features = features*np.asarray(distance_mod)\n",
    "    printable_features = gr_song_features[:,:9]\n",
    "    \n",
    "    gr_top_g_indexer = get_core_genres(gr_song_genres)\n",
    "    core_features = features[gr_top_g_indexer]\n",
    "    projection = tsne_projection(core_features)\n",
    "    plot3(projection, genres, color=gr_song_genres[gr_top_g_indexer])\n",
    "    print('')\n",
    "    print('mean features for all songs in group')\n",
    "    gr_song_mean = np.mean(printable_features, axis=0)\n",
    "    # print(gr_song_mean)\n",
    "    print_features(gr_song_mean)\n",
    "    print('')\n",
    "    print('mean features for all songs in top genres')\n",
    "    gr_song_mean = np.mean(printable_features[gr_top_g_indexer], axis=0)\n",
    "    print_features(gr_song_mean)\n",
    "    print('')\n",
    "    print('outliers information')\n",
    "    outliers_info(features, core_features, gr_song_features, gr_song_names, genres)\n",
    "    print('')\n",
    "    print('computing TSNE projection')\n",
    "    projection = tsne_projection(weighted_features)\n",
    "    print('')\n",
    "    print('clustering with DPGMM')\n",
    "    y_pred = fit_dpgmm(weighted_features, n_components=10)\n",
    "    plot_clusters(projection, y_pred)\n",
    "    print('')\n",
    "    print('clustering with DBSCAN')\n",
    "    y_pred = fit_DBSCAN(weighted_features)\n",
    "    plot_clusters(projection, y_pred)\n",
    "    print('')\n",
    "    print('clustering with affinity propagation')\n",
    "    y_pred = fit_affinity_prop(weighted_features)\n",
    "    plot_clusters(projection, y_pred)\n",
    "    max_k = 10\n",
    "    print('')\n",
    "    print('detection no cluster with kmeans_gap_statistics')\n",
    "    nc = kmeans_gap_statistics(weighted_features, max_k)\n",
    "    print('got %i clusters' % nc)\n",
    "    print('')\n",
    "    print('detection no cluster with kmeans_silhouette')\n",
    "    nc = kmeans_silhouette(weighted_features, max_k)\n",
    "    print('got %i clusters' % nc)\n",
    "    print('')\n",
    "    print('detection no cluster with kmeans_f_of_K')\n",
    "    nc = kmeans_f_of_K(weighted_features, max_k)\n",
    "    print('got %i clusters -> used for plotting' % nc)\n",
    "    y_pred = fit_kmeans(weighted_features, nc)\n",
    "    plot_clusters(projection, y_pred)\n",
    "    print('')\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "def describe_song_group(group_name, group_id, distance_mod):\n",
    "    print('GROUP %s(%i) INFO' % (group_name, group_id))\n",
    "    print('--------------------------------------')\n",
    "    gr_song_features, gr_song_names = load_songs(select_song_group(group_id), count_song_group(group_id))\n",
    "    gr_song_features, gr_song_genres, _, _, _ = prepare_songs(gr_song_features, features_scaler)\n",
    "    describe_songs(gr_song_features, gr_song_names, gr_song_genres, distance_mod)\n",
    "    \n",
    "    \n",
    "def describe_song_genre(genre_name, distance_mod):\n",
    "    genre_id = genres_name[genre_name]\n",
    "    print('GENRE %s(%i) INFO' % (genre_name, genre_id))\n",
    "    print('--------------------------------------')\n",
    "    gr_song_features, gr_song_names = load_songs(select_song_in_genre(genre_id), count_song_in_genre(genre_id))\n",
    "    gr_song_features, gr_song_genres, _, _, _ = prepare_songs(gr_song_features, features_scaler)\n",
    "    describe_songs(gr_song_features, gr_song_names, gr_song_genres, distance_mod)    \n",
    "    \n",
    "    \n",
    "def describe_song_group_type(name, group_type, distance_mod):\n",
    "    print('GROUP TYPE %s(%i) INFO' % (name, group_type))\n",
    "    print('--------------------------------------')\n",
    "    gr_song_features, gr_song_names = load_songs(select_song_group_type(group_type), count_song_group_type(group_type))\n",
    "    gr_song_features, gr_song_genres, _, _, _ = prepare_songs(gr_song_features, features_scaler)\n",
    "    #for i in range(gr_song_features.shape[1]):\n",
    "    #    for j in range(gr_song_features.shape[0]):\n",
    "    #        if np.isnan(gr_song_features[j,i]):\n",
    "    #            print('nan detected x %i y %i' % (j,i))\n",
    "            \n",
    "    #for i in range(gr_song_features.shape[1]):\n",
    "    #    print('%i: %s' % (i, str(gr_song_features[np.isnan(gr_song_features[:,i]),i])))\n",
    "    describe_songs(gr_song_features, gr_song_names, gr_song_genres, distance_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# db.session.rollback()\n",
    "# describe_song_group('sarnecka library', 66, [3,0.3,1,0.5,1,1,1,5])\n",
    "# describe_song_group_type('sleep playlists', 1, [3,0.3,1,0.5,1,1,1,5])\n",
    "# describe_song_genre('warm drone', [3,0.3,1,0.5,1,1,1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from api import user_helper\n",
    "from spotify import spotify_helper\n",
    "import importlib\n",
    "importlib.reload(spotify_helper)\n",
    "\n",
    "\n",
    "spotify_helper.refresh_token_on_expired = True\n",
    "\n",
    "feature_minimum = np.min(song_features, axis=0)\n",
    "feature_maximum = np.max(song_features, axis=0)\n",
    "\n",
    "def f_val_prc(i, f):\n",
    "    return (f[i] - feature_minimum[i])/(feature_maximum[i] - feature_minimum[i])\n",
    "\n",
    "\n",
    "def is_sleep_song(features):\n",
    "    energy_val = f_val_prc(0, features)\n",
    "    return energy_val < 0.6\n",
    "\n",
    "\n",
    "def is_wakeup_song(features):\n",
    "    energy_val = f_val_prc(0, features)\n",
    "    return energy_val > 0.6\n",
    "    \n",
    "\n",
    "def sleepines(features):\n",
    "    #low energy(0), tempo(2), valence(7), danceability(8), loudness(6)\n",
    "    #high acousticness(4)    \n",
    "    \n",
    "    return 1 - f_val_prc(0, features) + 1 - f_val_prc(2, features)  + 1 - f_val_prc(8, features)#\\ #feature_maximum[2] - features[2]\n",
    "            # feature_maximum[8] - features[8] #+ feature_maximum[6] - features[6] #+ features[4] + feature_maximum[7] - features[7]\n",
    "\n",
    "    \n",
    "def wakefulness(features):\n",
    "    #low energy(0), tempo(2), valence(7), danceability(8), loudness(6)\n",
    "    #high acousticness(4)\n",
    "    energy = f_val_prc(0, features)\n",
    "    danceability = f_val_prc(8, features)\n",
    "    valence = f_val_prc(7, features)\n",
    "    return max(energy+valence, danceability+valence) #features[0] + features[8] + features[6] + features[7] #+ features[4] + feature_maximum[7] - features[7]\n",
    "\n",
    "\n",
    "def song2tracks(song_id):\n",
    "    #s = sqlselect([SongTracks.SpotifyId]).where(sqltext(\"SongId=:sid\"))\n",
    "    s = sqltext('SELECT SpotifyId FROM SongTracks WHERE SongId=%i' % song_id)\n",
    "    #print(s) # {'sid': song_id}\n",
    "    track_ids = []\n",
    "    for row in db.session.execute(s).fetchall():\n",
    "        #print('%i > %s' % (song_id, row[0]))\n",
    "        track_ids.append((song_id, row[0]))\n",
    "    return track_ids\n",
    "\n",
    "\n",
    "def save_playlist(spotify_user_id, playlist_name, song_ids):\n",
    "    user = user_helper.load_user(spotify_user_id)\n",
    "    song_mappings = []\n",
    "    for song_id in song_ids:\n",
    "        song_mappings.extend(song2tracks(song_id))\n",
    "    #print(song_mappings)\n",
    "    spotify_tracks, added_songs = spotify_helper.resolve_tracks_for_user(user, song_mappings)\n",
    "    tracks = [t['uri'] for t in spotify_tracks]\n",
    "    sp_user_pl = spotify_helper.get_or_create_playlist_by_name(user, playlist_name)        \n",
    "    # print(added_songs)\n",
    "    spotify_helper.set_playlist_content(user, sp_user_pl['id'], tracks)\n",
    "    return added_songs\n",
    "\n",
    "\n",
    "def outliers_to_playlists(user, name, features, core_features, gr_song_features, gr_song_names, genres):\n",
    "    # novelty detection\n",
    "    clf = sklearn.svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "    clf.fit(core_features)\n",
    "    y_pred_train = clf.predict(features)\n",
    "    print('%% of outliers in dataset: %f%%' % (y_pred_train[y_pred_train == -1].size * 100.0 / features.shape[0]))\n",
    "    y_decision_train = clf.decision_function(features)[:,0]\n",
    "    y_decision_train_sort = np.argsort(y_decision_train)\n",
    "    outliers = []\n",
    "    for sort_id in y_decision_train_sort[:20]:\n",
    "        if y_pred_train[sort_id] == -1:\n",
    "            song = gr_song_features[sort_id]\n",
    "            outliers.append(song[13])\n",
    "            print('song %s-%s(%i) is outlier with dist %f' % (gr_song_names[song[13]], genres[song[14]],\n",
    "                                                              song[13], y_decision_train[sort_id]))\n",
    "    #save_playlist('rudolfix-us', name + ' outliers', outliers)\n",
    "\n",
    "    print('')\n",
    "    ingroup = []\n",
    "    y_decision_train_sort = y_decision_train_sort[::-1]\n",
    "    for sort_id in y_decision_train_sort[:20]:\n",
    "        if y_pred_train[sort_id] == 1:\n",
    "            song = gr_song_features[sort_id]\n",
    "            ingroup.append(song[13])\n",
    "            print('song %s-%s(%i) is ingroup with dist %f' % (gr_song_names[song[13]], genres[song[14]],\n",
    "                                                              song[13], y_decision_train[sort_id]))            \n",
    "    # 1130122659\n",
    "    # 'rudolfix-us'\n",
    "    if len(ingroup) > 0:\n",
    "        save_playlist(user, name + ' ingroup', ingroup)\n",
    "        \n",
    "        \n",
    "def top_songs_with_affinity(gr_song_features, limit, f_affinity):\n",
    "    printable_features = gr_song_features[:,:9]\n",
    "    # is_aff_songs = np.apply_along_axis(f_affinity_treshold, 1, printable_features)    \n",
    "    # songs_with_affinity = printable_features[is_aff_songs]\n",
    "    # print(songs_with_affinity.shape)\n",
    "    features_affinity = np.zeros(len(printable_features), dtype=np.float32)\n",
    "    for s_id, f in enumerate(printable_features):\n",
    "        features_affinity[s_id] = f_affinity(f)\n",
    "    features_affinity_sorted_idx = np.argsort(features_affinity)\n",
    "    features_affinity_sorted_idx_rev = features_affinity_sorted_idx[::-1]\n",
    "    return features_affinity_sorted_idx_rev[:limit]\n",
    "        \n",
    "        \n",
    "\n",
    "def compute_genres_for_songs(gr_song_features, gr_song_genres, artists_genres, genre_affinity, affinity_threshold=0.45, \n",
    "                            genre_prevalence_threshold=0.02, genre_prevalence_count_threshold=10000):\n",
    "    artists_ids = gr_song_features[:,15] #np.unique(\n",
    "    genres_accu = []\n",
    "    for aid in artists_ids:\n",
    "        if aid in artists_genres:\n",
    "            genres_accu.extend(artists_genres[aid])\n",
    "    genres_count = np.bincount(genres_accu)\n",
    "    \n",
    "    # lambda f: (sleepines(f)-min_sleepiness)/(max_sleepiness-min_sleepiness)\n",
    "    # genre_sleepiness = np.apply_along_axis(sleepines, 1, genre_features)\n",
    "    #print(genres_count.shape)\n",
    "    #print(genre_sleepiness.shape)\n",
    "    #genres_count_weighted = np.multiply(genres_count,genre_sleepiness[:len(genres_count)])\n",
    "    tot_in_sleep = sum(genres_count[genre_affinity[:len(genres_count)]>affinity_threshold])\n",
    "    # print(tot_in_sleep)\n",
    "    #print(genres_count_weighted.shape)\n",
    "    top_sleep_genres = []\n",
    "    g_bin_sort = np.argsort(genres_count)[::-1]\n",
    "    for i in g_bin_sort:\n",
    "        cnt = genres_count[i]\n",
    "        prevalence = cnt / tot_in_sleep\n",
    "        # mind the OR below\n",
    "        if  genre_affinity[i] > affinity_threshold and \\\n",
    "                (cnt > genre_prevalence_count_threshold or prevalence > genre_prevalence_threshold):\n",
    "            print('%s(%i): %i(%f%%) affinity:%f' % (genres[i], i, cnt, 100.0*prevalence, genre_affinity[i]))\n",
    "            top_sleep_genres.append((i, prevalence, genre_sleepiness[i]))\n",
    "            # print('')\n",
    "            # print_features(genre_features[i])\n",
    "            #print('---------------------')\n",
    "    \n",
    "    return top_sleep_genres\n",
    "\n",
    "def describe_clusters(name, gr_song_features, y_pred, gr_song_names, gr_song_genres):\n",
    "    y_pred = y_pred + 1\n",
    "    print('%s %s' % (name, np.bincount(y_pred)))\n",
    "    print('--------------------------')\n",
    "    for i, c in enumerate(np.bincount(y_pred)):\n",
    "        if c>0:\n",
    "            print('Cluster %i' % i)\n",
    "            print('---------------------')\n",
    "            describe_songs(gr_song_features[y_pred==i], gr_song_names, gr_song_genres[y_pred==i])\n",
    "            \n",
    "def clusters_to_playlists(user, name, gr_song_features, y_pred, gr_song_names, gr_song_genres):\n",
    "    y_pred = y_pred + 1\n",
    "    print('%s %s' % (name, np.bincount(y_pred)))\n",
    "    print('--------------------------')\n",
    "    for i, c in enumerate(np.bincount(y_pred)):\n",
    "        if c>0:\n",
    "            print('Cluster %i' % i)\n",
    "            print('---------------------')\n",
    "            features = gr_song_features[y_pred==i][:,featured_features]\n",
    "            gr_top_g_indexer = get_core_genres(gr_song_genres[y_pred==i])\n",
    "            core_features = features[gr_top_g_indexer]\n",
    "            outliers_to_playlists(user, '%s cluster %i - ' % (name, i), features, core_features, gr_song_features[y_pred==i],\\\n",
    "                                    gr_song_names, genres)\n",
    "            \n",
    "def extract_sleepy_clusters(genre_id, dist_mod, f_affinity, f_has_affinity, show_clusters=False, song_limit=5000,\n",
    "                            preserve_clusters_size=0.2, min_cluster_affinity_level=0):\n",
    "    gr_song_features, gr_song_names = load_songs(select_song_in_genre(genre_id, song_limit), count_song_in_genre(genre_id, song_limit))\n",
    "    gr_song_features, gr_song_genres, _, _, _ = prepare_songs(gr_song_features, features_scaler)\n",
    "    # remove songs without affinity (sleepy, wakeful etc)\n",
    "    gr_songs_affinity = np.apply_along_axis(f_has_affinity, 1, gr_song_features)\n",
    "    gr_song_features = gr_song_features[gr_songs_affinity]\n",
    "    gr_song_genres = gr_song_genres[gr_songs_affinity]\n",
    "    features = gr_song_features[:,featured_features]\n",
    "    printable_features = gr_song_features[:,:9]\n",
    "    weighted_features = features*np.asarray(dist_mod)\n",
    "    # get clusters\n",
    "    y_pred = fit_dpgmm(weighted_features, 12)\n",
    "    print('cluster sizes: %s' % str(np.bincount(y_pred)))\n",
    "    if show_clusters:\n",
    "        print('computing TSNE projection')\n",
    "        projection = tsne_projection(weighted_features)\n",
    "        plot_clusters(projection, y_pred)\n",
    "    #find clusters > 30% of all elements    \n",
    "    significant_clusters = []\n",
    "    cluster_sizes = np.bincount(y_pred)\n",
    "    for i, c in  enumerate(cluster_sizes):\n",
    "        if c / len(y_pred) > preserve_clusters_size:\n",
    "            significant_clusters.append([i,c])\n",
    "    if len(significant_clusters) == 0:\n",
    "        #add biggest cluster\n",
    "        max_c_idx = np.argmax(cluster_sizes)\n",
    "        significant_clusters.append([max_c_idx,cluster_sizes[max_c_idx]])\n",
    "    print(significant_clusters)\n",
    "    #remove outliers\n",
    "    for cluster in significant_clusters:        \n",
    "        cluster_songs_affinity = []\n",
    "        cluster_songs = []\n",
    "        cluster_id = cluster[0]        \n",
    "        cluster_features = weighted_features[y_pred==cluster_id]\n",
    "        gr_cluster_features = gr_song_features[y_pred==cluster_id]\n",
    "        clf = sklearn.svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "        clf.fit(cluster_features)\n",
    "        novelty_pred = clf.predict(cluster_features)\n",
    "        print('%% of outliers in dataset: %f%%' % (novelty_pred[novelty_pred == -1].size * 100.0 / cluster_features.shape[0]))\n",
    "        novelty_decision = clf.decision_function(cluster_features)[:,0]\n",
    "        novelty_decision_sort = np.argsort(novelty_decision)[::-1]    \n",
    "        for sort_id in novelty_decision_sort:\n",
    "            if novelty_pred[sort_id] == 1:\n",
    "                song = gr_cluster_features[sort_id]                \n",
    "                cluster_songs_affinity.append(f_affinity(song))\n",
    "                cluster_songs.append(song)\n",
    "        cluster.append(np.array(cluster_songs))\n",
    "        cluster.append(np.mean(cluster_songs_affinity))\n",
    "    #print(significant_clusters)\n",
    "    #return cluster list (cluster_id, size, songs, sleepiness)\n",
    "    return [c for c in significant_clusters if c[3] > min_cluster_affinity_level] #leave only sleepy clusters\n",
    "\n",
    "\n",
    "def compute_genre_features():\n",
    "    genre_features = np.zeros((len(genres), 9), dtype=np.float32)\n",
    "    genre_sleepiness = np.zeros((len(genres)), dtype=np.float32)\n",
    "    genre_wakefulness = np.zeros((len(genres)), dtype=np.float32)\n",
    "    for genre_id in genres:\n",
    "        genre_songs = song_features[song_genres==genre_id][:,:9]        \n",
    "        if genre_songs.shape[0] > 0:\n",
    "            genre_songs_sleepiness = np.apply_along_axis(lambda f: 1 if is_sleep_song(f) else 0, 1, genre_songs)\n",
    "            genre_songs_wakefulness = np.apply_along_axis(lambda f: 1 if is_wakeup_song(f) else 0, 1, genre_songs)\n",
    "            mean = np.mean(genre_songs, axis=0)\n",
    "            genre_features[genre_id] = mean\n",
    "            genre_sleepiness[genre_id] = np.mean(genre_songs_sleepiness)\n",
    "            genre_wakefulness[genre_id] = np.mean(genre_songs_wakefulness)\n",
    "            \n",
    "    return genre_features, genre_sleepiness, genre_wakefulness\n",
    "\n",
    "\n",
    "def similar_genres_from_similar_artists(artists_genres, connected_metric_f=len, use_foreign_sim=True):\n",
    "    # init similarity with genre co-occurence\n",
    "    genre_similarity = {}\n",
    "    \n",
    "    def proc_l2l(g_l, s_g_l):\n",
    "        for gid in g_l:\n",
    "            if gid not in genre_similarity:\n",
    "                g_dict = {}\n",
    "                genre_similarity[gid] = g_dict\n",
    "            else:\n",
    "                g_dict = genre_similarity[gid]\n",
    "            for s_gid in s_g_l:\n",
    "                if s_gid != gid:\n",
    "                    if s_gid not in g_dict:\n",
    "                        g_dict[s_gid] = 1\n",
    "                    else:\n",
    "                        g_dict[s_gid] += 1\n",
    "                        \n",
    "    for g_l in artists_genres.values():\n",
    "        if len(g_l) == 1:\n",
    "            continue\n",
    "        # all genres on the list co-occur\n",
    "        proc_l2l(g_l, g_l)\n",
    "                        \n",
    "    \n",
    "    if use_foreign_sim:\n",
    "        txt = 'SELECT ArtistId, SimilarArtistId, Dist FROM SimilarArtists ORDER BY ArtistId, Dist'\n",
    "        s = sqltext(txt)    \n",
    "        rows = db.session.execute(s).fetchall()\n",
    "        rc = 0\n",
    "        for row in rows:\n",
    "            if row[0] in artists_genres and row[1] in artists_genres:\n",
    "                proc_l2l(artists_genres[row[0]], artists_genres[row[1]])\n",
    "            if rc % 100000 == 0:\n",
    "                print(rc)\n",
    "            rc += 1            \n",
    "            # rows = db.session.execute(s).fetchmany()\n",
    "                        \n",
    "    #find maximally connected genre\n",
    "    max_g = max([(i[0], connected_metric_f(i[1].values())) for i in genre_similarity.items()], key=itemgetter(1))\n",
    "    #print(max_g)\n",
    "    #print(genres[max_g[0]])\n",
    "    #normalize weights\n",
    "    for gid in genre_similarity:\n",
    "        g_dict = genre_similarity[gid]\n",
    "        for s_gid in list(g_dict.keys()):\n",
    "            if g_dict[s_gid] > 3:\n",
    "                g_dict[s_gid] = 1 - connected_metric_f([g_dict[s_gid]]) / max_g[1]\n",
    "            else:\n",
    "                g_dict.pop(s_gid)\n",
    "    \n",
    "    return genre_similarity    \n",
    "\n",
    "\n",
    "# finds closest vector to ref_song among songs using feature indexes 'distance_features', euclidean distance\n",
    "def find_closest_song(ref_song, songs, distance_features, randlimit=5):\n",
    "    def ec_dist(song):\n",
    "        # print(zip(list(ref_song[distance_features]), list(song[distance_features])))\n",
    "        return math.sqrt(functools.reduce(\n",
    "                lambda y,x: y + (x[0]-x[1])**2, zip(ref_song[distance_features], song[distance_features]), 0))\n",
    "    distances = np.apply_along_axis(ec_dist,1,songs)\n",
    "    #print(distances[:100])\n",
    "    min_dis_idx =  np.argsort(distances)[:randlimit][random.randint(0,min(randlimit-1,len(distances)-1))]\n",
    "    #print(distances[min_dis_idx])\n",
    "    return min_dis_idx\n",
    "\n",
    "def compute_genre_similarity_graph(genre_similarity):\n",
    "    G_G = nx.Graph()\n",
    "    # similar_genres = load_similar_genres() # poor and not fully connected graph\n",
    "    # similar_genres = similar_genres_from_similar_artists(artists_genres, connected_metric_f=lambda x: math.log(sum(x))\n",
    "    for gid, simgenres in genre_similarity.items():\n",
    "        for simg in simgenres.items():\n",
    "            G_G.add_edge(gid, simg[0], weight=simg[1])\n",
    "    return G_G\n",
    "\n",
    "\n",
    "def display_graph(G, with_labels=False):\n",
    "    pylab.figure(1, figsize=(100, 100))\n",
    "    # layout graphs with positions using graphviz neato\n",
    "    pos = graphviz_layout(G_G, prog=\"neato\")\n",
    "    nx.draw(G_G, pos,\n",
    "                 node_size=40,\n",
    "                 vmin=0.0,\n",
    "                 vmax=1.0,\n",
    "                 with_labels=with_labels)\n",
    "\n",
    "\n",
    "def k_shortest_paths(G, source, target, k, weight=None):\n",
    "    return list(islice(nx.shortest_simple_paths(G, source, target, weight=weight), k))\n",
    "\n",
    "\n",
    "def edges_path_iter(G, path, data=False):\n",
    "    for i in range(len(path)-1):\n",
    "        n1 = path[i]\n",
    "        n2 = path[i+1]\n",
    "        if data is not False:\n",
    "            yield (n1, n2, G.edge[n1][n2][data])\n",
    "        else:\n",
    "            yield (n1, n2, G.edge[n1][n2])\n",
    "\n",
    "\n",
    "\n",
    "def find_closest_genre(G, gid, possible_genres):\n",
    "    shortest_paths = []\n",
    "    for possible_gid in possible_genres:\n",
    "        try:\n",
    "            for path in k_shortest_paths(G, gid, possible_gid, 1, weight='weight'):\n",
    "                w = functools.reduce(lambda w, edge: w + edge[2], edges_path_iter(G, path, data='weight'), 0 )\n",
    "                shortest_paths.append((path, w))                \n",
    "                #print('%s:%f' % ([genres[g]for g in path], w))\n",
    "        except nx.NetworkXNoPath:\n",
    "            pass\n",
    "        \n",
    "    if not shortest_paths:\n",
    "        return None\n",
    "    return sorted(shortest_paths, key=itemgetter(1))[0][0][-1]\n",
    "\n",
    "\n",
    "def fing_closest_genre_by_acoustics(ref_genre, genre_features, distance_features):\n",
    "    return find_closest_song(ref_genre, genre_features, distance_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute genre-wide stats\n",
    "db.session.rollback()\n",
    "artists_genres = load_artist_genres()\n",
    "genre_features, genre_sleepiness, genre_wakefulness = compute_genre_features()\n",
    "# do not use foreign-similarity. artist self similarity (genre occurence) produces fully connected graph\n",
    "# except czech pop ;>\n",
    "genre_similarity = similar_genres_from_similar_artists(artists_genres, connected_metric_f=lambda x: sum(x),\n",
    "                                                    use_foreign_sim=False)\n",
    "G_genre_sim = compute_genre_similarity_graph(genre_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "db.session.rollback()\n",
    "#describe_song_genre('warm drone', [3,0.3,1,0.5,1,1,1,5])\n",
    "# genre_id = genres_name['warm drone']\n",
    "# gr_song_features, gr_song_names = load_songs(select_song_in_genre(genre_id, 5000), count_song_in_genre(genre_id, 5000))\n",
    "#gr_song_features, gr_song_names = load_songs(select_song_group_type(1), count_song_group_type(1))\n",
    "# gr_song_features = gr_song_features[gr_song_features[:,14]>0]\n",
    "gr_song_features, gr_song_names = load_songs(select_song_group(66), count_song_group(66))\n",
    "gr_song_features, gr_song_genres, _, _, _ = prepare_songs(gr_song_features, features_scaler)\n",
    "# apply genre sleepiness\n",
    "    #else:\n",
    "    #    print('genre %s %i not present in dataset' % (genres[genre_id], genre_id))\n",
    "# genre_sleepiness = np.zeros((len(genres)+1, 1), dtype=np.float32)\n",
    "#max_sleepiness = sleepines(feature_maximum[:9])\n",
    "#min_sleepiness = sleepines(feature_minimum[:9])\n",
    "\n",
    "#gr_g_array = np.array(gr_song_genres, dtype=np.int64)\n",
    "#gr_g_bins = np.bincount(gr_g_array)\n",
    "#gr_g_bin_sort = np.argsort(gr_g_bins)[::-1]\n",
    "#for i, cnt in enumerate(gr_g_bins):\n",
    "#    if cnt > 0:\n",
    "#        print('%s: %i' % (genres[i], cnt))\n",
    "#print(repr(gr_g_bins))\n",
    "#print(len(gr_g_bins))\n",
    "#print(gr_g_bin_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambient idm(42): 16(8.888889%) affinity:0.464358\n",
      "glitch(620): 14(7.777778%) affinity:0.700143\n",
      "modern performance(893): 12(6.666667%) affinity:0.977929\n",
      "minimal(879): 12(6.666667%) affinity:0.921856\n",
      "dream pop(471): 12(6.666667%) affinity:0.613687\n",
      "ethereal wave(524): 12(6.666667%) affinity:0.661905\n",
      "classical christmas(260): 9(5.000000%) affinity:0.990141\n",
      "choral(218): 9(5.000000%) affinity:1.000000\n",
      "dub techno(481): 9(5.000000%) affinity:0.611684\n",
      "warm drone(1358): 8(4.444444%) affinity:0.893130\n",
      "fourth world(566): 7(3.888889%) affinity:0.902247\n",
      "ambient(39): 7(3.888889%) affinity:0.923516\n",
      "dark ambient(329): 6(3.333333%) affinity:0.813411\n",
      "lowercase(828): 6(3.333333%) affinity:0.866667\n",
      "abstract idm(5): 6(3.333333%) affinity:0.471891\n",
      "hauntology(668): 6(3.333333%) affinity:0.643939\n",
      "throat singing(1271): 5(2.777778%) affinity:0.888889\n",
      "\n",
      "progressive psytrance(1056): 11(5.583756%) affinity:0.859736\n",
      "breakcore(139): 10(5.076142%) affinity:0.877680\n",
      "mathcore(847): 9(4.568528%) affinity:0.924863\n",
      "metalcore(869): 8(4.060914%) affinity:0.940877\n",
      "ebm(495): 7(3.553299%) affinity:0.859404\n",
      "futurepop(590): 7(3.553299%) affinity:0.914235\n",
      "power noise(1046): 7(3.553299%) affinity:0.836439\n",
      "aggrotech(20): 7(3.553299%) affinity:0.951311\n",
      "electro-industrial(507): 7(3.553299%) affinity:0.908019\n",
      "polish hip hop(1014): 6(3.045685%) affinity:0.804004\n",
      "chaotic hardcore(197): 6(3.045685%) affinity:0.884615\n",
      "abstract hip hop(4): 6(3.045685%) affinity:0.693515\n",
      "blues-rock(117): 6(3.045685%) affinity:0.673745\n",
      "underground hip hop(1320): 6(3.045685%) affinity:0.786547\n",
      "classic rock(251): 6(3.045685%) affinity:0.673913\n",
      "doom metal(464): 6(3.045685%) affinity:0.754321\n",
      "melodic metalcore(858): 5(2.538071%) affinity:0.956835\n",
      "lithumania(819): 5(2.538071%) affinity:0.681633\n",
      "synthpop(1252): 4(2.030457%) affinity:0.726673\n",
      "ambient psychill(43): 4(2.030457%) affinity:0.721519\n",
      "deep breakcore(349): 4(2.030457%) affinity:0.795322\n",
      "screamo(1134): 4(2.030457%) affinity:0.901042\n",
      "death core(340): 4(2.030457%) affinity:0.937415\n",
      "electroclash(509): 4(2.030457%) affinity:0.751938\n",
      "electronic(511): 4(2.030457%) affinity:0.759091\n",
      "swedish synthpop(1243): 4(2.030457%) affinity:0.845528\n",
      "new rave(943): 4(2.030457%) affinity:0.801939\n",
      "indietronica(714): 4(2.030457%) affinity:0.794872\n",
      "alternative dance(26): 4(2.030457%) affinity:0.810056\n",
      "\n",
      "metalcore(869): 138(5.305652%) affinity:0.059123\n",
      "mathcore(847): 118(4.536717%) affinity:0.075137\n",
      "death core(340): 116(4.459823%) affinity:0.062585\n",
      "melodic metalcore(858): 110(4.229143%) affinity:0.043165\n",
      "breakcore(139): 105(4.036909%) affinity:0.122320\n",
      "ambient idm(42): 103(3.960015%) affinity:0.464358\n",
      "screamo(1134): 78(2.998847%) affinity:0.098958\n",
      "drill and bass(473): 76(2.921953%) affinity:0.422727\n",
      "progressive psytrance(1056): 70(2.691273%) affinity:0.140264\n",
      "power noise(1046): 65(2.499039%) affinity:0.163561\n",
      "abstract idm(5): 55(2.114571%) affinity:0.471891\n",
      "glitch(620): 45(1.730104%) affinity:0.700143\n",
      "chaotic hardcore(197): 43(1.653210%) affinity:0.115385\n",
      "dub techno(481): 40(1.537870%) affinity:0.611684\n",
      "deep melodic metalcore(404): 40(1.537870%) affinity:0.088136\n",
      "djent(461): 37(1.422530%) affinity:0.159468\n",
      "funeral doom(582): 32(1.230296%) affinity:0.604215\n",
      "deep breakcore(349): 31(1.191849%) affinity:0.204678\n",
      "psychill(1066): 27(1.038062%) affinity:0.395210\n",
      "underground hip hop(1320): 27(1.038062%) affinity:0.213453\n",
      "doom metal(464): 27(1.038062%) affinity:0.245679\n",
      "lithumania(819): 27(1.038062%) affinity:0.318367\n",
      "abstract hip hop(4): 27(1.038062%) affinity:0.306485\n",
      "post-metal(1040): 25(0.961169%) affinity:0.404365\n",
      "groove metal(644): 23(0.884275%) affinity:0.068602\n",
      "christian metal(225): 23(0.884275%) affinity:0.107447\n",
      "deep dub techno(369): 22(0.845829%) affinity:0.514403\n",
      "futurepop(590): 20(0.768935%) affinity:0.085765\n",
      "aggrotech(20): 20(0.768935%) affinity:0.048689\n",
      "electro-industrial(507): 20(0.768935%) affinity:0.091981\n",
      "ebm(495): 20(0.768935%) affinity:0.140596\n",
      "death metal(341): 19(0.730488%) affinity:0.037445\n",
      "brutal deathcore(157): 19(0.730488%) affinity:0.058824\n",
      "technical death metal(1258): 19(0.730488%) affinity:0.090909\n",
      "technical brutal death metal(1257): 19(0.730488%) affinity:0.070946\n",
      "swedish metal(1236): 18(0.692042%) affinity:0.059767\n",
      "pop punk(1027): 17(0.653595%) affinity:0.098168\n",
      "post-hardcore(1039): 17(0.653595%) affinity:0.229611\n",
      "vaporwave(1330): 15(0.576701%) affinity:0.476489\n",
      "microhouse(877): 14(0.538255%) affinity:0.491543\n",
      "polish hip hop(1014): 14(0.538255%) affinity:0.195996\n",
      "acid jazz(9): 14(0.538255%) affinity:0.318237\n",
      "drone metal(476): 14(0.538255%) affinity:0.485788\n",
      "atmospheric post-metal(63): 13(0.499808%) affinity:0.442060\n",
      "ambient(39): 13(0.499808%) affinity:0.923516\n",
      "nu gaze(972): 12(0.461361%) affinity:0.222938\n",
      "minimal(879): 12(0.461361%) affinity:0.921856\n",
      "shoegaze(1150): 12(0.461361%) affinity:0.385393\n",
      "ethereal wave(524): 12(0.461361%) affinity:0.661905\n",
      "polish pop(1017): 12(0.461361%) affinity:0.460417\n",
      "nu metal(974): 12(0.461361%) affinity:0.111111\n",
      "grave wave(636): 12(0.461361%) affinity:0.389247\n",
      "hauntology(668): 12(0.461361%) affinity:0.643939\n",
      "polish indie(1015): 12(0.461361%) affinity:0.426056\n",
      "dream pop(471): 12(0.461361%) affinity:0.613687\n",
      "modern performance(893): 12(0.461361%) affinity:0.977929\n",
      "indie shoegaze(712): 12(0.461361%) affinity:0.397820\n",
      "polish punk(1018): 12(0.461361%) affinity:0.076642\n",
      "jazz metal(769): 11(0.422914%) affinity:0.195349\n",
      "hardcore(659): 11(0.422914%) affinity:0.062945\n",
      "straight edge(1218): 11(0.422914%) affinity:0.106383\n",
      "blackgaze(113): 11(0.422914%) affinity:0.390681\n",
      "christian hardcore(223): 11(0.422914%) affinity:0.129231\n",
      "intelligent dance music(722): 11(0.422914%) affinity:0.383349\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BABUBA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-565-ace6beb58649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m                                      genre_prevalence_threshold=0.01, genre_prevalence_count_threshold=10)\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mBABUBA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# y_pred = fit_kmeans(genres_one_hot, 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BABUBA' is not defined"
     ]
    }
   ],
   "source": [
    "db.session.rollback()\n",
    "\n",
    "    \n",
    "most_n_indexer = top_songs_with_affinity(gr_song_features, 100, sleepines)\n",
    "most_song_features = gr_song_features[most_n_indexer]\n",
    "#print(gr_song_features.shape)\n",
    "most_song_genres = gr_song_genres[most_n_indexer]\n",
    "most_features = most_song_features[:,featured_features]\n",
    "most_printable_features = most_song_features[:,:9]\n",
    "top_sleep_genres = compute_genres_for_songs(most_song_features, most_song_genres, artists_genres, genre_sleepiness)\n",
    "\n",
    "\n",
    "print('')\n",
    "most_n_indexer = top_songs_with_affinity(gr_song_features, 100, wakefulness)\n",
    "most_song_features = gr_song_features[most_n_indexer]\n",
    "#print(gr_song_features.shape)\n",
    "most_song_genres = gr_song_genres[most_n_indexer]\n",
    "most_features = most_song_features[:,featured_features]\n",
    "most_printable_features = most_song_features[:,:9]\n",
    "\n",
    "top_wake_genres = compute_genres_for_songs(most_song_features, most_song_genres, artists_genres, genre_wakefulness,\n",
    "                                          affinity_threshold=0.65, genre_prevalence_threshold=0.02)\n",
    "print('')\n",
    "\n",
    "genre_prevalence_threshold = min(10/gr_song_features.shape[0], 0.01) # 10 or more songs or 1%\n",
    "top_genres = compute_genres_for_songs(gr_song_features, gr_song_genres, artists_genres, genre_sleepiness, affinity_threshold=0,\n",
    "                                     genre_prevalence_threshold=0.01, genre_prevalence_count_threshold=10)\n",
    "\n",
    "BABUBA()\n",
    "\n",
    "# y_pred = fit_kmeans(genres_one_hot, 3)\n",
    "# print(gr_song_features.shape)\n",
    "# print(y_pred.shape)\n",
    "# print(gr_song_genres.shape)\n",
    "# y_pred = fit_kmeans(features, 3)\n",
    "# describe_clusters('combined', gr_song_features, y_pred, gr_song_names, gr_song_genres)\n",
    "# y_pred = fit_kmeans(features, 3)\n",
    "#spotify_account = '1130122659'\n",
    "spotify_account = 'rudolfix-us'\n",
    "dist_mod_sleep = [3,0.3,1,0.5,1,1,1,5]\n",
    "dist_mod_library = [3,0.3,1,0.5,2,2,1,3]\n",
    "for sleep_genre in top_sleep_genres:\n",
    "    genre_id,_,_ = sleep_genre\n",
    "    sleep_clusters = extract_sleepy_clusters(genre_id, dist_mod_sleep, show_clusters=False)\n",
    "    print('genre %s: (%s)' % (genres[genre_id], str(sleep_genre)))\n",
    "    print([(c1,c2,len(c3),c4) for c1, c2, c3, c4 in sleep_clusters])\n",
    "    for s_c in sleep_clusters:\n",
    "        #print(s_c[2][:100][13])\n",
    "        pl_name = 'sleep %s c %i' % (genres[genre_id], s_c[0])\n",
    "        print(pl_name)\n",
    "        save_playlist(spotify_account, pl_name, s_c[2][:100,13])\n",
    "        print('------')\n",
    "#weighted_features = features*np.asarray(dist_mod_sleep)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#clusters_to_playlists(spotify_account, 'acoustic features', gr_song_features, y_pred, gr_song_names, gr_song_genres)\n",
    "#describe_clusters('acoustic features', gr_song_features, y_pred, gr_song_names, gr_song_genres)\n",
    "#y_pred = fit_kmeans(genres_one_hot, 3)\n",
    "#describe_clusters('genres_one_hot', gr_song_features, y_pred, gr_song_names, gr_song_genres)\n",
    "\n",
    "#print(song_features.shape)\n",
    "#print(features.shape)\n",
    "#spotify_account = '1130122659'\n",
    "features_sleepiness = np.zeros(len(printable_features), dtype=np.float32)\n",
    "for s_id, f in enumerate(printable_features):\n",
    "    features_sleepiness[s_id] = sleepines(f)\n",
    "features_sleepiness_sorted_idx = np.argsort(features_sleepiness)\n",
    "features_sleepiness_sorted_idx_rev = features_sleepiness_sorted_idx[::-1]\n",
    "\n",
    "ingroup = []\n",
    "for s in gr_song_features[features_sleepiness_sorted_idx_rev[:40],:]:\n",
    "    print(gr_song_names[s[13]] + '(%i)' % s[13])\n",
    "    #print_features(s)\n",
    "    # print()\n",
    "    ingroup.append(s[13])\n",
    "#save_playlist(spotify_account, 'most sleepy', ingroup)\n",
    "\n",
    "\n",
    "features_wakefullness = np.zeros(len(printable_features), dtype=np.float32)\n",
    "for s_id, f in enumerate(printable_features):\n",
    "    features_wakefullness[s_id] = wakefullness(f)\n",
    "features_wakefullness_sorted_idx = np.argsort(features_wakefullness)\n",
    "features_wakefullness_sorted_idx_rev = features_wakefullness_sorted_idx[::-1]\n",
    "print('---------------------')\n",
    "ingroup = []\n",
    "for s in gr_song_features[features_wakefullness_sorted_idx_rev[:40],:]:\n",
    "    print(gr_song_names[s[13]] + '(%i)' % s[13])\n",
    "    #print_features(s)\n",
    "    # print()\n",
    "    ingroup.append(s[13])\n",
    "\n",
    "#save_playlist(spotify_account, 'least sleepy', ingroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster sizes: [   0    0  104 1116    0  208    0    0  224    0    0  384]\n",
      "[[3, 1116]]\n",
      "% of outliers in dataset: 9.946237%\n",
      "[1134, 1086, 1308, 1365, 3]\n",
      "processing screamo\n",
      "cluster sizes: [1618    0    0 1260    0  266    0    0    0    0 1162]\n",
      "[[0, 1618], [3, 1260], [10, 1162]]\n",
      "% of outliers in dataset: 10.259580%\n",
      "% of outliers in dataset: 9.682540%\n",
      "% of outliers in dataset: 9.982788%\n",
      "3636\n",
      "----by Before Their Eyes\n",
      "processing rap rock\n",
      "----------replaced with metalcore(869)\n",
      "cluster sizes: [2480  341    0  129    0    0    0  844  187    0  526]\n",
      "[[0, 2480]]\n",
      "% of outliers in dataset: 10.040323%\n",
      "2231\n",
      "----by Converge\n",
      "processing rap rock\n",
      "----------replaced with metalcore(869)\n",
      "cluster sizes: [2566    0    0  259    0  556  176    0    0    0    0  950]\n",
      "[[0, 2566], [11, 950]]\n",
      "% of outliers in dataset: 10.054560%\n",
      "% of outliers in dataset: 9.789474%\n",
      "3165\n",
      "----by Zao\n",
      "processing turntablism\n",
      "----------replaced with abstract hip hop(4)\n",
      "cluster sizes: [ 675 2495  807    0    0  101    0  143  474    0  305]\n",
      "[[1, 2495]]\n",
      "% of outliers in dataset: 9.939880%\n",
      "2247\n",
      "----by Buck 65\n",
      "processing turntablism\n",
      "----------replaced with abstract hip hop(4)\n",
      "cluster sizes: [1015    0 2302    0    0    0  602  495    0    0    0  586]\n",
      "[[0, 1015], [2, 2302]]\n",
      "% of outliers in dataset: 10.147783%\n",
      "% of outliers in dataset: 10.034752%\n",
      "2983\n",
      "----by Classified\n",
      "processing wonky\n",
      "----------replaced with glitch(620)\n",
      "cluster sizes: [1052   81  457 1162  455  366   92  478    0   15  268  574]\n",
      "[[0, 1052], [3, 1162]]\n",
      "% of outliers in dataset: 9.600760%\n",
      "% of outliers in dataset: 10.240964%\n",
      "1994\n",
      "----by Mouse on Mars\n",
      "processing wonky\n",
      "cluster sizes: [217 133   0 802   0   0 252   0  50   0 227 208]\n",
      "[[3, 802]]\n",
      "% of outliers in dataset: 10.224439%\n",
      "----by Heralds of Change\n",
      "processing abstract beats\n",
      "cluster sizes: [1226    0    0    0   13    0  104  261  200    0  232]\n",
      "[[0, 1226]]\n",
      "% of outliers in dataset: 10.032626%\n",
      "----by Heralds of Change\n"
     ]
    }
   ],
   "source": [
    "def generate_wakeup_playlist(wake_gid, wake_song_features, wake_song_genres, gr_song_features, gr_song_genres, top_sleep_genres,\n",
    "                            top_genres):\n",
    "    # find #start genre song and then #end genre with speechiness, acousticness and instru as close as possible\n",
    "    # morph energy, temp, dance, valence linearly    \n",
    "    # wake_song_features has wakeful songs filtered for current user\n",
    "    init_song_idx = list(most_song_genres).index(wake_gid) # find the most wakeful song of given gid\n",
    "    # todo: replace first song with other metrics like general popularity, when user added etc.\n",
    "    # todo: extend with song from similar artists\n",
    "    init_song = most_song_features[init_song_idx]\n",
    "    # find matchin end genre from sleep genres by speechiness, acousticness and instru\n",
    "    sound_similarity = [3,4,5]\n",
    "    energy_similarity = [0,2,8]\n",
    "    sound_energy_similarity = [0,3,4,5]\n",
    "    possible_sleep_genres = list(set([g[0] for g in top_sleep_genres]).intersection(list(np.unique(gr_song_genres.astype(int)))))\n",
    "    end_gid = fing_closest_genre_by_acoustics(genre_features[847], genre_features[np.asarray(possible_sleep_genres, dtype=np.int32)],\n",
    "                                              sound_similarity)\n",
    "    sleepy_clusters = extract_sleepy_clusters(end_gid, dist_mod_sleep, sleepines, is_sleep_song, show_clusters=False)\n",
    "    end_songs = np.vstack(c[2] for c in sleepy_clusters)\n",
    "    end_song_idx = find_closest_song(init_song, end_songs, sound_similarity,1)\n",
    "    end_song = end_songs[end_song_idx]\n",
    "    # use genre similarity graph to connect wake_gid to end_gid\n",
    "    genre_path=[]\n",
    "    try:\n",
    "        for path in k_shortest_paths(G_genre_sim, wake_gid, end_gid, 1, weight='weight'):\n",
    "            genre_path = path\n",
    "            print(path)\n",
    "    except nx.NetworkXNoPath:\n",
    "        raise # todo: handle NetworkXNoPath somehow        \n",
    "    # morph song into end song in genre_path steps\n",
    "    genre_path = [g for g in genre_path for _ in (0, 1)]\n",
    "    song_diff = (end_song - init_song) / (len(genre_path) - 1)\n",
    "    # var below will be morphed\n",
    "    song_iter = np.copy(end_song)\n",
    "    wakeup_playlist = [init_song[13]]\n",
    "    possible_genres = list(set([g[0] for g in top_genres]).intersection(list(np.unique(gr_song_genres.astype(int)))))\n",
    "    \n",
    "    def replace_closest_gid(gid):\n",
    "        # print(possible_genres)\n",
    "        if gid not in possible_genres:\n",
    "            c_gid = find_closest_genre(G_genre_sim, gid, possible_genres)\n",
    "            if c_gid is not None:\n",
    "                print('----------replaced with %s(%i)' % (genres[c_gid], c_gid))\n",
    "                return c_gid\n",
    "\n",
    "        return gid\n",
    "\n",
    "    for i in range(1, len(genre_path)-1):\n",
    "        song_iter += song_diff\n",
    "        print('processing %s' % genres[genre_path[i]])\n",
    "        gid = genre_path[i]\n",
    "        # choose afinity func\n",
    "        if i <= len(genre_path) // 3:\n",
    "            f_affinity = wakefulness\n",
    "            f_has_affinity = is_wakeup_song\n",
    "            dist_index = energy_similarity\n",
    "            gid = replace_closest_gid(gid)\n",
    "            # todo: below cerain number of songs extend by artist or to full genre\n",
    "            #c_songs = gr_song_features[gr_song_genres==gid]\n",
    "            clusters = extract_sleepy_clusters(gid, dist_mod_sleep, f_affinity, f_has_affinity, show_clusters=False)\n",
    "            c_songs = np.vstack(c[2] for c in clusters)\n",
    "            print(len(c_songs))\n",
    "        elif i <= 2*len(genre_path) // 3:\n",
    "            f_affinity = lambda x: 1 #identity\n",
    "            f_has_affinity = lambda x: True        \n",
    "            dist_index = energy_similarity\n",
    "            gid = replace_closest_gid(gid)\n",
    "            # todo: below cerain number of songs extend by artist or to full genre\n",
    "            #c_songs = gr_song_features[gr_song_genres==gid]\n",
    "            clusters = extract_sleepy_clusters(gid, dist_mod_sleep, f_affinity, f_has_affinity, show_clusters=False)\n",
    "            c_songs = np.vstack(c[2] for c in clusters)\n",
    "            print(len(c_songs))\n",
    "        else:\n",
    "            f_affinity = sleepines\n",
    "            f_has_affinity = is_sleep_song\n",
    "            dist_index = sound_energy_similarity\n",
    "            # find any song from cluster\n",
    "            clusters = extract_sleepy_clusters(gid, dist_mod_sleep, f_affinity, f_has_affinity, show_clusters=False)\n",
    "            c_songs = np.vstack(c[2] for c in clusters)\n",
    "\n",
    "        c_song_idx = find_closest_song(song_iter, c_songs,dist_index)\n",
    "        print('----by %s' % get_artists_name(c_songs[c_song_idx][15]))\n",
    "        wakeup_playlist.append(c_songs[c_song_idx][13])\n",
    "    wakeup_playlist.append(end_song[13])\n",
    "    \n",
    "    return wakeup_playlist\n",
    "\n",
    "wakeup_playlist = generate_wakeup_playlist(1134, most_song_features,\n",
    "                                           most_song_genres, gr_song_features, gr_song_genres, top_sleep_genres, top_genres)\n",
    "#print(wakeup_playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 481    5   39   42  620  879  471 1271  218  668]\n",
      "42\n",
      "ambient idm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "# find_closest_genres(G_genre_sim, genres_name['psychedelic trance'], [g[0] for g in top_genres])\n",
    "# G_genre_sim.edge[1065][378]\n",
    "possible_genres = list(set([g[0] for g in top_sleep_genres]).intersection(list(np.unique(gr_song_genres.astype(int)))))\n",
    "print(np.asarray(possible_genres))\n",
    "closest_gid = fing_closest_genre_by_acoustics(genre_features[847], genre_features[np.asarray(possible_genres, dtype=np.int32)], [3,4,5])\n",
    "print(possible_genres[closest_gid])\n",
    "print(genres[possible_genres[closest_gid]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2653311.0, 1831300.0, 1831300.0, 48353.0, 1046594.0, 501622.0, 689883.0, 882508.0, 228294.0, 227559.0]\n",
      "{1046594.0, 2653311.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# comp\n",
    "#print_features(most_printable_features[init_song_idx])\n",
    "#print('')\n",
    "#print_features(end_songs[end_song_idx][:9])\n",
    "# save\n",
    "pl_name = 'wake me up 3'\n",
    "spotify_account = 'rudolfix-us'\n",
    "#save_playlist(spotify_account, pl_name, [init_song[13], end_songs[end_song_idx][13]])\n",
    "added_songs = save_playlist(spotify_account, pl_name, wakeup_playlist[::-1])\n",
    "print(wakeup_playlist[::-1])\n",
    "print(set(wakeup_playlist).difference(added_songs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spotify:track:1N81UrowQOnFls2csPFBAz', 'spotify:track:1YC6I5egSCYkCdID1CZMAt', 'spotify:track:3fd8OekZV9WVhrg4fQw0xR', 'spotify:track:65be8oawWem4SpeqABuL62', 'spotify:track:0MItBzDaZzBBzOeiZnuW1a', 'spotify:track:21tWM1trHeoDI2XkTXIbfR', 'spotify:track:1fFts1wzm6WMifjbO7HeIl']\n"
     ]
    }
   ],
   "source": [
    "save_playlist(spotify_account, pl_name, wakeup_playlist[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progressive psytrance(1056):\n",
      "deep psytrance(421) 0.013263\n",
      "psychedelic trance(1065) 0.005637\n",
      "full on(581) 0.004642\n",
      "[(621, 0.10084)]\n",
      "glitch beats\n"
     ]
    }
   ],
   "source": [
    "#print(artists_genres.values())\n",
    "db.session.rollback()\n",
    "similar_genres = similar_genres_from_similar_artists(artists_genres, connected_metric_f=lambda x: sum(x),\n",
    "                                                    use_foreign_sim=False)\n",
    "#gid = top_sleep_genres[0][0]\n",
    "gid = top_wake_genres[0][0]\n",
    "simg = similar_genres[gid].items()\n",
    "simg = sorted(simg, key=itemgetter(1))[::-1]\n",
    "print('%s(%i):' % (genres[gid], gid))\n",
    "for sg in simg:\n",
    "    print('%s(%i) %f'%(genres[sg[0]], sg[0], sg[1]))\n",
    "similar_genres2 = load_similar_genres()\n",
    "simg = similar_genres2[top_sleep_genres[0][0]]\n",
    "print(simg)\n",
    "for sg in simg:\n",
    "    print(genres[sg[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i, g_id in enumerate(genre_sleepiness_sorted_idx_rev):  # work on reverse\n",
    "    if g_id in genres:\n",
    "        max_nb = min(i+5, len(genre_sleepiness_sorted_idx))  # 5 neighbours\n",
    "        for nb in range(i+1, max_nb):\n",
    "            n_g_id = genre_sleepiness_sorted_idx_rev[nb]\n",
    "            if n_g_id in genres: #genre_sleepiness[n_g_id] - genre_sleepiness[g_id]\n",
    "                G.add_edge(genres[g_id], genres[n_g_id], weight=genre_sleepiness[g_id] - genre_sleepiness[n_g_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_G = nx.Graph()\n",
    "# similar_genres = load_similar_genres()\n",
    "# similar_genres = similar_genres_from_similar_artists(artists_genres, connected_metric_f=lambda x: math.log(sum(x))\n",
    "genre_similarity = similar_genres_from_similar_artists(artists_genres, connected_metric_f=lambda x: sum(x),\n",
    "                                                    use_foreign_sim=False)\n",
    "for gid, simgenres in genre_similarity.items():\n",
    "    for simg in simgenres.items():\n",
    "        G_G.add_edge(genres[gid], genres[simg[0]], weight=simg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.figure(1, figsize=(100, 100))\n",
    "# layout graphs with positions using graphviz neato\n",
    "pos = graphviz_layout(G_G, prog=\"neato\")\n",
    "nx.draw(G_G, pos,\n",
    "             node_size=40,\n",
    "             vmin=0.0,\n",
    "             vmax=1.0,\n",
    "             with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progressive psytrance -> ambient idm\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'intelligent dance music', 'ambient idm']\n",
      "progressive psytrance -> glitch\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'glitch']\n",
      "progressive psytrance -> modern performance\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'glitch', 'drone', 'modern performance']\n",
      "progressive psytrance -> minimal\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'glitch', 'drone', 'minimal']\n",
      "progressive psytrance -> dream pop\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'wonky', 'indie r&b', 'dream pop']\n",
      "progressive psytrance -> ethereal wave\n",
      "['progressive psytrance', 'psychedelic trance', 'psychill', 'world fusion', 'medieval', 'ethereal wave']\n",
      "progressive psytrance -> classical christmas\n",
      "['progressive psytrance', 'psychedelic trance', 'psychill', 'ambient', 'new age', 'classical christmas']\n",
      "progressive psytrance -> choral\n",
      "['progressive psytrance', 'psychedelic trance', 'psychill', 'ambient', 'new age', 'classical christmas', 'choral']\n",
      "progressive psytrance -> dub techno\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'glitch', 'dub techno']\n",
      "progressive psytrance -> warm drone\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'glitch', 'warm drone']\n",
      "progressive psytrance -> fourth world\n",
      "['progressive psytrance', 'psychedelic trance', 'psychill', 'ambient', 'fourth world']\n",
      "progressive psytrance -> ambient\n",
      "['progressive psytrance', 'psychedelic trance', 'psychill', 'ambient']\n",
      "progressive psytrance -> dark ambient\n",
      "['progressive psytrance', 'psychedelic trance', 'psychill', 'ambient', 'dark ambient']\n",
      "progressive psytrance -> lowercase\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'glitch', 'lowercase']\n",
      "progressive psytrance -> abstract idm\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'intelligent dance music', 'ambient idm', 'abstract idm']\n",
      "progressive psytrance -> hauntology\n",
      "['progressive psytrance', 'deep psytrance', 'glitch hop', 'glitch', 'hauntology']\n",
      "progressive psytrance -> throat singing\n",
      "['progressive psytrance', 'psychedelic trance', 'psychill', 'world fusion', 'healing', 'tibetan', 'throat singing']\n"
     ]
    }
   ],
   "source": [
    "# print(G['disco house'])\n",
    "# print(G['deep alternative r&b'])\n",
    "\n",
    "#paths = list(nx.shortest_simple_paths(G, 'deep alternative r&b', 'disco house'))\n",
    "#print(paths)\n",
    "\n",
    "#'disco house'\n",
    "from_g_name = genres[top_wake_genres[0][0]]\n",
    "for gid,_,_ in top_sleep_genres:\n",
    "    to_g_name = genres[gid]\n",
    "    print('%s -> %s' % (from_g_name, to_g_name))\n",
    "    shortest = nx.dijkstra_path(G_G, from_g_name, to_g_name, weight='weight')\n",
    "    try:\n",
    "        for path in k_shortest_paths(G_G, from_g_name, to_g_name, 1, weight='weight'):\n",
    "            simplest = path\n",
    "            print(path)\n",
    "    except nx.NetworkXNoPath:\n",
    "        print ('no path')\n",
    "        path = []\n",
    "    diff = set(shortest).symmetric_difference(simplest)\n",
    "    if len(diff) > 0:\n",
    "        print(shortest)\n",
    "        print(simplest)\n",
    "        print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MGSongGroup():\n",
    "    def __init__(self, name, group_id):\n",
    "        self.name = name\n",
    "        self.group_id = group_id\n",
    "        self.gr_song_features, self.gr_song_names = load_songs(select_song_group(group_id),\n",
    "                                                               count_song_group(group_id))\n",
    "        self.gr_song_features, self.gr_song_genres, _, _, _ = prepare_songs(self.gr_song_features, features_scaler)\n",
    "        self.features = self.gr_song_features[:,featured_features]\n",
    "        self.printable_features = self.gr_song_features[:,:9]\n",
    "    \n",
    "        self.gr_top_g_indexer = get_core_genres(self.gr_song_genres, describe=False)\n",
    "        self.core_features = self.features[self.gr_top_g_indexer]\n",
    "        self.clf = sklearn.svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "        self.clf.fit(self.core_features)\n",
    "        self.y_pred, self.fit_prc, self.y_decision = self.compute_outliers(self.features)        \n",
    "        \n",
    "    def compute_outliers(self, more_features):\n",
    "        if more_features.shape[0] == 0:\n",
    "            return None, 0, None\n",
    "        y_pred = self.clf.predict(more_features)\n",
    "        fit_prc = 100-(y_pred[y_pred == -1].size * 100.0 / more_features.shape[0])\n",
    "        y_decision = self.clf.decision_function(more_features)[:,0]\n",
    "        return y_pred, fit_prc, y_decision\n",
    "    \n",
    "    @property\n",
    "    def ingroup_features(self):\n",
    "        return self.features[self.y_pred==1]\n",
    "    \n",
    "    @property\n",
    "    def outlier_features(self):\n",
    "        return self.features[self.y_pred==-1]\n",
    "        \n",
    "    def describe_outliers(self, y_pred, fit_prc, y_decision, gr_song_features, gr_song_names):\n",
    "        print('%% of outliers in dataset: %f%%' % fit_prc)\n",
    "        y_decision_sort = np.argsort(y_decision)\n",
    "        for sort_id in y_decision_sort[:20]:\n",
    "            if y_pred[sort_id] == -1:\n",
    "                song = gr_song_features[sort_id]\n",
    "                print('song %s-%s(%i) is outlier with dist %f' % (gr_song_names[song[13]], genres[song[14]],\n",
    "                                                                  song[13], y_decision[sort_id]))\n",
    "        print('most crazy outlier')\n",
    "        print(print_features(gr_song_features[y_decision_sort[0],0:9]))\n",
    "\n",
    "        print('')\n",
    "        y_decision_sort = y_decision_sort[::-1]\n",
    "        for sort_id in y_decision_sort[:20]:\n",
    "            if y_pred[sort_id] == 1:\n",
    "                song = gr_song_features[sort_id]\n",
    "                print('song %s-%s(%i) is ingroup with dist %f' % (gr_song_names[song[13]], genres[song[14]],\n",
    "                                                                  song[13], y_decision[sort_id]))\n",
    "        print('most ingrouped')\n",
    "        print(print_features(gr_song_features[y_decision_sort[0],0:9]))\n",
    "        \n",
    "    def describe_self(self):\n",
    "        self.describe_outliers(self.y_pred, self.fit_prc, self.y_decision, self.gr_song_features, self.gr_song_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.session.rollback()\n",
    "# describe_song_group(\"ambient\", 31)\n",
    "group_30 = MGSongGroup(\"rfix library\", 66)\n",
    "# group_30.describe_self()\n",
    "# describe_song_group_type('FALL ASLEEP', 1)\n",
    "for gr in db.session.query(Group).order_by(Group.GroupId):\n",
    "    group = MGSongGroup(gr.Name, gr.GroupId)\n",
    "    _, ext_fit, _ = group_30.compute_outliers(group.features)\n",
    "    _, ext_fit_ing, _ = group_30.compute_outliers(group.ingroup_features)\n",
    "    print('group %s (%i) fit into group %s = %f vs %f ING, self fit %f' % \n",
    "          (group.name, group.group_id, group_30.name, ext_fit, ext_fit_ing, group.fit_prc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.max(song_genres)\n",
    "#np.bincount(song_genres[1:1000])\n",
    "# song_genres[1:1000]/1383.0\n",
    "#song_names[1:1000].shape\n",
    "#projection[:,2]\n",
    "#flabels = song_names[song_genres < 10]\n",
    "#len(flabels)\n",
    "#print(len(genres))\n",
    "#print(np.mean(song_features, axis=0))\n",
    "#print(np.std(song_features, axis=0))\n",
    "#print(np.max(song_features, axis=0))\n",
    "#print(np.min(song_features, axis=0))\n",
    "#projection\n",
    "#genres\n",
    "#for i, label in enumerate(genres):\n",
    "#    print('%i - %s' % (i,label))\n",
    "#print(np.mean(genre_features, axis=0))\n",
    "#print(np.std(genre_features, axis=0))\n",
    "#print(np.max(genre_features, axis=0))\n",
    "#print(np.min(genre_features, axis=0))\n",
    "# print(song_names[9943])\n",
    "# print(song_features[song_features[:, 13] == 9943])\n",
    "# print(song_features[song_features[:, 14] == 10, 0])\n",
    "print(np.mean(song_features[song_features[:, 14] == 10, 0]))\n",
    "print(genre_features[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featured_features = [0,1,2,3,4,5,7,8]\n",
    "features = gr_song_features[:,featured_features]\n",
    "\n",
    "n_clusters_ = 6\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "connectivity = kneighbors_graph(features, n_neighbors=10, include_self=False)\n",
    "\n",
    "cls = sklearn.cluster.AgglomerativeClustering(n_clusters=n_clusters_, connectivity=connectivity, linkage='ward')\n",
    "cls.fit(features)\n",
    "y_pred = cls.labels_\n",
    "# [{'node_id': next(itertools.count(X.shape[0])), 'left': x[0], 'right':x[1]} for x in clustering.children_]\n",
    "print('No of clusters %i' % n_clusters_)\n",
    "# print(y_pred)\n",
    "y_pred = y_pred + 1\n",
    "print(np.bincount(y_pred))\n",
    "components = {0: 'noise samples'}\n",
    "for c in range(1, n_clusters_+1):\n",
    "    components[c] = 'component %i' % c\n",
    "projection = tsne_projection(features) #\n",
    "plot3(projection, components, color=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make one hot encoded features for genres\n",
    "genres_one_hot = np.zeros([gr_song_features.shape[0], len(genres)])\n",
    "print(genres_one_hot.shape)\n",
    "#print(artists_genres)\n",
    "for row in range(gr_song_features.shape[0]):\n",
    "    s = gr_song_features[row]\n",
    "    if s[15] in artists_genres:\n",
    "        for g in artists_genres[s[15]]:\n",
    "            genres_one_hot[row,g-1] = 1\n",
    "# combine features\n",
    "combined = np.hstack((features, genres_one_hot))\n",
    "max_k = 10\n",
    "nc = 6\n",
    "#print('')\n",
    "#print('detection no cluster with kmeans_gap_statistics')\n",
    "#nc = kmeans_gap_statistics(combined, max_k)\n",
    "#print('got %i clusters' % nc)\n",
    "print('')\n",
    "print('detection no cluster with kmeans_silhouette')\n",
    "# nc = kmeans_silhouette(combined, max_k)\n",
    "print('got %i clusters' % nc)\n",
    "print('')\n",
    "print('detection no cluster with kmeans_f_of_K')\n",
    "# nc = kmeans_f_of_K(combined, max_k)\n",
    "print('got %i clusters -> used for plotting' % nc)\n",
    "# y_pred = fit_kmeans(features, 6)\n",
    "for i, n in enumerate(feature_names):\n",
    "    print('%i: %s' % (i,n))\n",
    "dist_mod_sleep = [3,0.3,1,0.5,1,1,1,5]\n",
    "dist_mod_library = [3,0.3,1,0.5,2,2,1,3]\n",
    "weighted_features = features*np.asarray(dist_mod_sleep)\n",
    "print('computing TSNE projection')\n",
    "#projection = tsne_projection(weighted_features)\n",
    "#y_pred = fit_dpgmm(weighted_features, 12)\n",
    "plot_clusters(projection, y_pred)\n",
    "\n",
    "#describe_clusters('combined', gr_song_features, y_pred, gr_song_names, gr_song_genres)\n",
    "#clusters_to_playlists('clustered library', gr_song_features, y_pred, gr_song_names, gr_song_genres)\n",
    "clusters_to_playlists('acoustic features', gr_song_features, y_pred, gr_song_names, gr_song_genres)\n",
    "pca = sklearn.decomposition.PCA(n_components=50) # \n",
    "pca_proj = pca.fit(combined).transform(combined)\n",
    "\n",
    "fit_kmeans(genres_one_hot, 3)\n",
    "fit_kmeans(pca_proj, 3)\n",
    "fit_kmeans(combined, 3)\n",
    "fit_kmeans(features, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
